<!DOCTYPE html>
<html lang="">
    <!-- title -->




<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="InTheBloodHorse">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="InTheBloodHorse">
    <meta name="keywords" content="Hexo | InTheBloodHorse">
    <meta name="description" content="">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>机器学习(2) 决策树(ID3算法实现) · InTheBloodHorse&#39;blog</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/assets/favicon.png" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
        <!-- algolia -->
        <script>
            
            var hits = JSON.parse('{"per_page":10}')
            var labels = JSON.parse('{"input_placeholder":"Search for Posts","hits_empty":"We did not find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}')

            var algolia = {
                applicationID: 'IRQ4MI9TZ5',
                apiKey: '0b3a4b664df3becae08f01c1d7866dee',
                indexName: '1niblog',
                hits: hits,
                labels: labels
            }
        </script>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</head>

    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >InTheBloodHorse</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">机器学习(2) 决策树(ID3算法实现)</a>
            </div>
    </div>
    
    <a class="home-link" href=/>InTheBloodHorse</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            机器学习(2) 决策树(ID3算法实现)
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                
                    <div class="post-intro-read">
                        <span>字数统计: <span class="post-count word-count">2.7k</span>阅读时长: <span class="post-count reading-time">11 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2018/09/22</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <h2 id="决策树简介"><a href="#决策树简介" class="headerlink" title="决策树简介"></a>决策树简介</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>决策树，顾名思义就是选择，通过问答的形式，针对每一次问答，来推断分解，逐步缩小待猜测事物的范围。<br>即：问问题，回答，每回答一次，根据答案走到下一层，当没得走了，就是得到了结果了。下图为决策树的流程。<img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922165959.jpg" alt="TIM截图20180922165959.jpg"></p>
<h3 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a>决策树的构造</h3><p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据<br>缺点：可能会产生过度匹配问题<br>使用数据类型：数值型和标称型</p>
<h4 id="构造细节"><a href="#构造细节" class="headerlink" title="构造细节"></a>构造细节</h4><p>在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。为了寻找决定性的特征，划分出最好的结果，我们就必须评估每个特征。然后对数据进行划分，直到<br>某个分支下的数据属于同一个类型，表明这个分支已经区分完了。<br>下面是伪代码<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922170920.jpg" alt="TIM截图20180922170920.jpg"></p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>(1) 收集数据：可以使用任何方法。<br>(2) 准备数据：决策树构造算法只适用于标称型数据，因此数据型数据必须离散化。<br>(3) 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。<br>(4) 训练算法：构造树的数据结构。<br>(5) 测试算法：使用经验书计算错误率。<br>(6) 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。</p>
<p>测试特征包括：不浮出水面是否可以生存，以及是否有脚蹼。我们可以将这些动物分成两类：鱼类和非鱼类。现在我们想要决定依据第一个特征还是第二个特征。如图：<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922171354.jpg" alt="TIM截图20180922171354.jpg"></p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>划分数据集的大原则是：将无序的数据变得更加有序。<br>在划分数据集之前之后信息发生的变化成为信息增益，我们可以计算每个特征值划分数据获得的信息增益，获得信息增益最高的特征就是最好的选择。在这里我们可以用过计算熵来实现</p>
<h3 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h3><p>熵定义为信息的期望值，在明晰这个概念之前，我们必须知道信息的定义。如果待分类的事物可能划分在多个分类之中，信息定义为<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922201952.jpg" alt="TIM截图20180922201952.jpg"><br>其中P(Xi)是选择该分类的概率。<br>为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，可以通过下面的公式得到：<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922202448.jpg" alt="TIM截图20180922202448.jpg">其中n是分类的数目<br>计算香农熵的Python代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_shannon_ent</span><span class="params">(data_set)</span>:</span></span><br><span class="line">    <span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line">    <span class="comment"># 总数目</span></span><br><span class="line">    sum_number = len(data_set)</span><br><span class="line">    label_counts = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_set:</span><br><span class="line">        current_label = data[<span class="number">-1</span>]</span><br><span class="line">        label_counts[current_label] = label_counts.get(current_label, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    shanno_ent = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> label_counts.items():</span><br><span class="line">        <span class="comment"># 求概率</span></span><br><span class="line">        prob = float(value) / sum_number</span><br><span class="line">        <span class="comment"># 对应的公式</span></span><br><span class="line">        shanno_ent -= prob * log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shanno_ent</span><br></pre></td></tr></table></figure></p>
<p>然后我们就需要测试数据了(和第三张图对应)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_data_set</span><span class="params">()</span>:</span></span><br><span class="line">    data_set = [</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]</span><br><span class="line">    ]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> data_set, labels</span><br></pre></td></tr></table></figure></p>
<p>测试的结果为 0.9709505944546686<br><strong>熵越高，则混合的数据也越多，我们可以在数据集中添加更多的分类，观察熵是如何变化的。</strong><br>比如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_set, label = create_data_set()</span><br><span class="line">data_set[<span class="number">0</span>][<span class="number">-1</span>] = <span class="string">'maybe'</span></span><br><span class="line">ent1 = calc_shannon_ent(data_set)</span><br><span class="line">print(ent1)</span><br></pre></td></tr></table></figure></p>
<p>得到的结果是 1.3709505944546687<br>得到熵之后，我们就可以按照获取最大信息增益的方法划分数据集。</p>
<h3 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h3><p>按照给定特征划分数据集<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data_set</span><span class="params">(data_set, axis, value)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param data_set: 待区分的数据集</span></span><br><span class="line"><span class="string">    :param axis: 特征值</span></span><br><span class="line"><span class="string">    :param value: 特征值返回的数值</span></span><br><span class="line"><span class="string">    :return: 区分好的数据集</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    ret_data_set = []</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_set:</span><br><span class="line">        <span class="keyword">if</span> data[axis] == value:</span><br><span class="line">            <span class="comment"># 接下来两步的目的是pop data[axis]</span></span><br><span class="line">            reduce_data = data[:axis]</span><br><span class="line">            reduce_data.extend(data[axis + <span class="number">1</span>:])</span><br><span class="line">            ret_data_set.append(reduce_data)</span><br><span class="line">    <span class="keyword">return</span> ret_data_set</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到 每个数据说第0位 == 0 的数据集</span></span><br><span class="line">spilt = split_data_set(data_set, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">print(spilt)</span><br><span class="line"><span class="comment">#[[1, 'no'], [1, 'no']]</span></span><br></pre></td></tr></table></figure>
<p>接下来我们将遍历整个数据集，循环计算香农熵和split_data_set()函数，找到最好的特征划分方式。熵计算将会告诉我们如何划分数据集是最好的数据组织方式。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_best_feature_to_split</span><span class="params">(data_set)</span>:</span></span><br><span class="line">    <span class="comment"># 除去最后一位 也就是 label位</span></span><br><span class="line">    num_value = len(data_set[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 初始 香农熵，会和后面的进行比较</span></span><br><span class="line">    base_entropy = calc_shannon_ent(data_set)</span><br><span class="line">    best_gain = <span class="number">0.0</span>  <span class="comment"># 当前最大的信息增益</span></span><br><span class="line">    best_gain_index = <span class="number">-1</span>  <span class="comment"># 能够得到最大信息增益的index</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_value):</span><br><span class="line">        <span class="comment"># 创建唯一的分类标签列表</span></span><br><span class="line">        data_list = [data[i] <span class="keyword">for</span> data <span class="keyword">in</span> data_set]</span><br><span class="line">        unique_data_list = set(data_list)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每种划分方式的信息熵</span></span><br><span class="line">        new_entropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> unique_data_list:</span><br><span class="line">            sub_data_set = split_data_set(data_set, i, value)</span><br><span class="line">            prob = len(sub_data_set) / float(len(data_set))</span><br><span class="line">            new_entropy += prob * calc_shannon_ent(sub_data_set)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 比较，计算出最好的信息增益</span></span><br><span class="line">        dis_gain = base_entropy - new_entropy</span><br><span class="line">        <span class="keyword">if</span> dis_gain &gt; best_gain:</span><br><span class="line">            best_gain = dis_gain</span><br><span class="line">            best_gain_index = i</span><br><span class="line">    <span class="keyword">return</span> best_gain_index</span><br></pre></td></tr></table></figure></p>
<p>这个函数是遍历当前特征种的所有唯一属性值，对每个特征划分一次数据集，然后计算数据集中的新熵值，并对所有唯一特征值得到的熵求和。信息增益是熵的减少或者是数据无序度的减少。最后比较所有特征中的信息增益，返回最好特征划分的索引值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> print(choose_best_feature_to_split(data_set))</span><br><span class="line"><span class="comment"># 0</span></span><br></pre></td></tr></table></figure></p>
<p>我们可以看到输出的结果是0，说明第0个特征是最好的用于划分数据集的特征。实际上我们去比较一下，会发现结果是正确的。</p>
<h3 id="递归构建决策树"><a href="#递归构建决策树" class="headerlink" title="递归构建决策树"></a>递归构建决策树</h3><p>下面思考一个问题：递归什么时候结束？<br>1：当我们区分出来的数据都是同一个类别的时候，停止。<br>2：当我们判断的特征全部用完的时候，自然也都全部停止了。<br>先完②的代码，当全部用完的时候，我们可能还没有完全区分出数据，所以我们需要筛选，遍历完所有特征时返回出现次数最多的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majority_cnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    class_count = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        class_count[vote] = class_count.get(vote, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> sorted(class_count.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>这个代码和我们讲K-近邻算法的规则相似，也容易理解，这里便不多解释。<br>接下来就是创建树<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(data_set, label)</span>:</span></span><br><span class="line">    <span class="comment"># 得到一个新的labels，因为后续有del的操作，会改变原列表，会造成某些bug，所以这里创建一个新的</span></span><br><span class="line">    labels = label[:]</span><br><span class="line">    <span class="comment"># 创建 标签，判断结束条件</span></span><br><span class="line">    class_list = [data[<span class="number">-1</span>] <span class="keyword">for</span> data <span class="keyword">in</span> data_set]</span><br><span class="line">    <span class="keyword">if</span> class_list.count(class_list[<span class="number">0</span>]) == len(class_list):</span><br><span class="line">        <span class="keyword">return</span> class_list[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(data_set[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> majority_cnt(class_list)</span><br><span class="line">    <span class="comment"># 得到最好的划分特征索引</span></span><br><span class="line">    best_feat = choose_best_feature_to_split(data_set)</span><br><span class="line">    best_feat_label = labels[best_feat]</span><br><span class="line"></span><br><span class="line">    my_tree = &#123;best_feat_label: &#123;&#125;&#125;</span><br><span class="line">    <span class="comment"># 与删除已经区分的label</span></span><br><span class="line">    <span class="keyword">del</span> labels[best_feat]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获得唯一特征值</span></span><br><span class="line">    feat_values = [data[best_feat] <span class="keyword">for</span> data <span class="keyword">in</span> data_set]</span><br><span class="line">    feat_values_set = set(feat_values)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> feat_values_set:</span><br><span class="line">        <span class="comment"># 复制标签，这样原数据不会被改变</span></span><br><span class="line">        sub_labels = labels[:]</span><br><span class="line">        my_tree[best_feat_label][value] = create_tree(</span><br><span class="line">            <span class="comment"># 根据 最好的划分数据索引 得到的特征值 来生成新的数据集</span></span><br><span class="line">            split_data_set(data_set, best_feat, value),</span><br><span class="line">            sub_labels)</span><br><span class="line">    <span class="keyword">return</span> my_tree</span><br></pre></td></tr></table></figure></p>
<p>最后代码遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数 create_tree()，得到的返回值将被插入到字典变量my_tree中。<br>测试代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(create_tree(data_set, label))</span><br><span class="line"><span class="comment"># &#123;'no surfacing': &#123;0: 'no', 1: &#123;'flippers': &#123;0: 'no', 1: 'yes'&#125;&#125;&#125;&#125;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="用Matplotlib注解绘制树形图"><a href="#用Matplotlib注解绘制树形图" class="headerlink" title="用Matplotlib注解绘制树形图"></a>用Matplotlib注解绘制树形图</h3><p>用字典的方式非常不易理解，所以采用绘图的方式（能力有限 PIL的内容不多介绍，抱歉）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> decision_tree.tree <span class="keyword">import</span> create_data_set, create_tree</span><br><span class="line"></span><br><span class="line">decisionNode = dict(boxstyle=<span class="string">"sawtooth"</span>, fc=<span class="string">"0.8"</span>)</span><br><span class="line">leafNode = dict(boxstyle=<span class="string">"round4"</span>, fc=<span class="string">"0.8"</span>)</span><br><span class="line">arrow_args = dict(arrowstyle=<span class="string">"&lt;-"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNumLeafs</span><span class="params">(myTree)</span>:</span></span><br><span class="line">    numLeafs = <span class="number">0</span></span><br><span class="line">    firstStr = list(myTree.keys())[<span class="number">0</span>]</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> type(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">            numLeafs += getNumLeafs(secondDict[key])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            numLeafs += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> numLeafs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTreeDepth</span><span class="params">(myTree)</span>:</span></span><br><span class="line">    maxDepth = <span class="number">0</span></span><br><span class="line">    firstStr = list(myTree.keys())[<span class="number">0</span>]</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> type(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">            thisDepth = <span class="number">1</span> + getTreeDepth(secondDict[key])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            thisDepth = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> thisDepth &gt; maxDepth: maxDepth = thisDepth</span><br><span class="line">    <span class="keyword">return</span> maxDepth</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotNode</span><span class="params">(nodeTxt, centerPt, parentPt, nodeType)</span>:</span></span><br><span class="line">    createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords=<span class="string">'axes fraction'</span>,</span><br><span class="line">                            xytext=centerPt, textcoords=<span class="string">'axes fraction'</span>,</span><br><span class="line">                            va=<span class="string">"center"</span>, ha=<span class="string">"center"</span>, bbox=nodeType, arrowprops=arrow_args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotMidText</span><span class="params">(cntrPt, parentPt, txtString)</span>:</span></span><br><span class="line">    xMid = (parentPt[<span class="number">0</span>] - cntrPt[<span class="number">0</span>]) / <span class="number">2.0</span> + cntrPt[<span class="number">0</span>]</span><br><span class="line">    yMid = (parentPt[<span class="number">1</span>] - cntrPt[<span class="number">1</span>]) / <span class="number">2.0</span> + cntrPt[<span class="number">1</span>]</span><br><span class="line">    createPlot.ax1.text(xMid, yMid, txtString, va=<span class="string">"center"</span>, ha=<span class="string">"center"</span>, rotation=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotTree</span><span class="params">(myTree, parentPt, nodeTxt)</span>:</span></span><br><span class="line">    numLeafs = getNumLeafs(myTree)</span><br><span class="line">    depth = getTreeDepth(myTree)</span><br><span class="line">    firstStr = list(myTree.keys())[<span class="number">0</span>]</span><br><span class="line">    cntrPt = (plotTree.xOff + (<span class="number">1.0</span> + float(numLeafs)) / <span class="number">2.0</span> / plotTree.totalW, plotTree.yOff)</span><br><span class="line">    plotMidText(cntrPt, parentPt, nodeTxt)</span><br><span class="line">    plotNode(firstStr, cntrPt, parentPt, decisionNode)</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    plotTree.yOff = plotTree.yOff - <span class="number">1.0</span> / plotTree.totalD</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> type(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">            plotTree(secondDict[key], cntrPt, str(key))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            plotTree.xOff = plotTree.xOff + <span class="number">1.0</span> / plotTree.totalW</span><br><span class="line">            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)</span><br><span class="line">            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))</span><br><span class="line">    plotTree.yOff = plotTree.yOff + <span class="number">1.0</span> / plotTree.totalD</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createPlot</span><span class="params">(inTree)</span>:</span></span><br><span class="line">    fig = plt.figure(<span class="number">1</span>, facecolor=<span class="string">'white'</span>)</span><br><span class="line">    fig.clf()</span><br><span class="line">    axprops = dict(xticks=[], yticks=[])</span><br><span class="line">    createPlot.ax1 = plt.subplot(<span class="number">111</span>, frameon=<span class="keyword">False</span>, **axprops)</span><br><span class="line">    plotTree.totalW = float(getNumLeafs(inTree))</span><br><span class="line">    plotTree.totalD = float(getTreeDepth(inTree))</span><br><span class="line">    plotTree.xOff = <span class="number">-0.5</span> / plotTree.totalW;</span><br><span class="line">    plotTree.yOff = <span class="number">1.0</span></span><br><span class="line">    plotTree(inTree, (<span class="number">0.5</span>, <span class="number">1.0</span>), <span class="string">''</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    data_set, labels = create_data_set()</span><br><span class="line">    dict_tree = create_tree(data_set, labels)</span><br><span class="line">    print(dict_tree)</span><br><span class="line">    createPlot(dict_tree)</span><br></pre></td></tr></table></figure></p>
<p>我们可以看到调用了creatPlot就可以呈现出我们的决策树<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922211714.jpg" alt="TIM截图20180922211714.jpg"></p>
<h3 id="测试算法：使用决策树执行分类"><a href="#测试算法：使用决策树执行分类" class="headerlink" title="测试算法：使用决策树执行分类"></a>测试算法：使用决策树执行分类</h3><p>我们通过训练数据构造了决策树之后，我们可以将它用于实际数据的分类。<br>决策树的分类函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classiyf</span><span class="params">(tree, labels, vecotr)</span>:</span></span><br><span class="line">    current_node = list(tree.keys())[<span class="number">0</span>]</span><br><span class="line">    next_dict = tree[current_node]</span><br><span class="line">    feat_index = labels.index(current_node)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> next_dict.keys():</span><br><span class="line">        <span class="keyword">if</span> vecotr[feat_index] == key:</span><br><span class="line">            <span class="comment"># 当前是决策节点</span></span><br><span class="line">            <span class="keyword">if</span> type(next_dict[key]).__name__ == <span class="string">'dict'</span>:</span><br><span class="line">                class_label = classiyf(next_dict[key], labels, vecotr)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 当前是叶子节点的话，就返回值</span></span><br><span class="line">                class_label = next_dict[key]</span><br><span class="line">    <span class="keyword">return</span> class_label</span><br></pre></td></tr></table></figure></p>
<p>递归函数，根据我们的传入的向量vector模拟我们的数据，一直走，直到叶子节点。<br>测试代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tree = create_tree(data_set, label)</span><br><span class="line">print(classiyf(tree, label, [<span class="number">1</span>, <span class="number">0</span>]))</span><br><span class="line">print(classiyf(tree, label, [<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># no</span></span><br><span class="line"><span class="comment"># yes</span></span><br></pre></td></tr></table></figure></p>
<p>从我们用PIL绘制的决策树图形可以看出，当我们第一步选择 1，第二步选择 0 时，返回的结果为 no，和我们分类函数返回的结果一致。</p>
<h3 id="使用算法-决策树的存储"><a href="#使用算法-决策树的存储" class="headerlink" title="使用算法:决策树的存储"></a>使用算法:决策树的存储</h3><p>因为我们每次构造决策树都非常的耗时，即使处理很小的数据集，我们可以用pickle序列化对象将我们训练好的模型存储起来<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">store_tree</span><span class="params">(tree, filename)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        pickle.dump(tree, f)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_tree</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        fr = open(filename)</span><br><span class="line">        <span class="keyword">return</span> pickle.load(fr)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">judge = get_tree(<span class="string">'tree_model'</span>)</span><br><span class="line"><span class="keyword">if</span> judge:</span><br><span class="line">   tree = judge</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">   tree = create_tree(data_set, label)</span><br><span class="line">   <span class="comment">#存储</span></span><br><span class="line">   store_tree(tree, <span class="string">'tree_model'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="示例：使用决策树预测隐形眼镜类型"><a href="#示例：使用决策树预测隐形眼镜类型" class="headerlink" title="示例：使用决策树预测隐形眼镜类型"></a>示例：使用决策树预测隐形眼镜类型</h3><p>代码完全一致 只是数据集变化了而已。（数据集在github，最下方）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data_set</span><span class="params">()</span>:</span></span><br><span class="line">    data_set = []</span><br><span class="line">    labels = [<span class="string">'age'</span>, <span class="string">'prescript'</span>, <span class="string">'astigmatic'</span>, <span class="string">'tearRate'</span>]</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'lenses.txt'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> f.readlines():</span><br><span class="line">            data_list = i.replace(<span class="string">'\t'</span>, <span class="string">','</span>).replace(<span class="string">'\n'</span>, <span class="string">''</span>).split(<span class="string">','</span>)</span><br><span class="line">            data_set.append(data_list)</span><br><span class="line">    <span class="keyword">return</span> data_set, labels</span><br><span class="line"></span><br><span class="line">data_set, labels = get_data_set()</span><br><span class="line">tree = create_tree(data_set, labels)</span><br><span class="line">createPlot(tree)</span><br></pre></td></tr></table></figure></p>
<p>我们可以观察到如图<br><img src="/2018/09/22/机器学习-2-决策树-ID3算法实现/TIM截图20180922213509.jpg" alt="TIM截图20180922213509.jpg"><br>关于机器学习的所有内容都会在<a href="https://github.com/BestOfDp/machine_learning_demo/tree/master/decision_tree" target="_blank" rel="noopener">GitHub</a><br>参考：《机器学习实战》</p>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>原文作者：<a href="http://pyking.cn">InTheBloodHorse</a>
            <p>原文链接：<a href="http://pyking.cn/2018/09/22/机器学习-2-决策树-ID3算法实现/">http://pyking.cn/2018/09/22/机器学习-2-决策树-ID3算法实现/</a>
            <p>发表日期：<a href="http://pyking.cn/2018/09/22/机器学习-2-决策树-ID3算法实现/">September 22nd 2018, 4:54:22 pm</a>
            <p>更新日期：<a href="http://pyking.cn/2018/09/22/机器学习-2-决策树-ID3算法实现/">September 22nd 2018, 9:45:05 pm</a>
            <p>版权声明：请随意转载！</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2018/09/23/每日一题-12-BZOJ1833/" title= "每日一题(12) BZOJ1833">
                    <div class="nextTitle">每日一题(12) BZOJ1833</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2018/09/21/每日一题-11-HDU4734/" title= "每日一题(11) HDU4734">
                    <div class="prevTitle">每日一题(11) HDU4734</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
    
        
            
                <a href="//github.com/BestOfDp" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <span class="iconfont-archer wechat" title=wechat>
                  
                  <img class="profile-qr" src="/assets/1ni.png" />
                </span>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树简介"><span class="toc-number">1.</span> <span class="toc-text">决策树简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#概念"><span class="toc-number">1.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#决策树的构造"><span class="toc-number">1.2.</span> <span class="toc-text">决策树的构造</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#构造细节"><span class="toc-number">1.2.1.</span> <span class="toc-text">构造细节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#流程"><span class="toc-number">1.3.</span> <span class="toc-text">流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#信息增益"><span class="toc-number">1.4.</span> <span class="toc-text">信息增益</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#熵"><span class="toc-number">1.5.</span> <span class="toc-text">熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#划分数据集"><span class="toc-number">1.6.</span> <span class="toc-text">划分数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#递归构建决策树"><span class="toc-number">1.7.</span> <span class="toc-text">递归构建决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#用Matplotlib注解绘制树形图"><span class="toc-number">1.8.</span> <span class="toc-text">用Matplotlib注解绘制树形图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#测试算法：使用决策树执行分类"><span class="toc-number">1.9.</span> <span class="toc-text">测试算法：使用决策树执行分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用算法-决策树的存储"><span class="toc-number">1.10.</span> <span class="toc-text">使用算法:决策树的存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#示例：使用决策树预测隐形眼镜类型"><span class="toc-number">1.11.</span> <span class="toc-text">示例：使用决策树预测隐形眼镜类型</span></a></li></ol></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 39
        </div>
        <!-- search  -->
        
            <div class="site-search popup-trigger">
                <span class="iconfont-archer search-icon">&#xe627;</span>
            </div>
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2018 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/09</span><a class="archive-post-title" href= "/2018/10/09/每日一题-26-codeforces-1051C/" >每日一题(26) codeforces 1051C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/08</span><a class="archive-post-title" href= "/2018/10/08/每日一题-25-codeforces-1051B/" >每日一题(25) codeforces 1051B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/07</span><a class="archive-post-title" href= "/2018/10/07/每日一题-24-codeforces-1051A/" >每日一题(24) codeforces 1051A</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/06</span><a class="archive-post-title" href= "/2018/10/06/SpringBoot笔记/" >SpringBoot笔记</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/06</span><a class="archive-post-title" href= "/2018/10/06/每日一题-23-codeforces1047C/" >每日一题(23) codeforces1047C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/05</span><a class="archive-post-title" href= "/2018/10/05/每日一题-22-codeforces-1047B/" >每日一题(22)codeforces 1047B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/04</span><a class="archive-post-title" href= "/2018/10/04/每日一题-21-codeforces-1047A/" >每日一题(21) codeforces 1047A</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/04</span><a class="archive-post-title" href= "/2018/10/04/数据结构与算法-7-树状数组/" >数据结构与算法(7) 树状数组</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/01</span><a class="archive-post-title" href= "/2018/10/01/每日一题-20-codeforces-1042B/" >每日一题(20) codeforces 1042B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/30</span><a class="archive-post-title" href= "/2018/09/30/每日一题-19-codeforces-1042A/" >每日一题(19) codeforces 1042A</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/30</span><a class="archive-post-title" href= "/2018/09/30/数据结构与算法-6-你可能不知道的斐波那契数列/" >数据结构与算法(6) 你可能不知道的斐波那契数列</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/29</span><a class="archive-post-title" href= "/2018/09/29/每日一题-18-codeforces-1041D/" >每日一题(18) codeforces 1041D</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/28</span><a class="archive-post-title" href= "/2018/09/28/每日一题-17-codeforces-1041C/" >每日一题(17) codeforces 1041C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/27</span><a class="archive-post-title" href= "/2018/09/27/每日一题-16-codeforces-1041B/" >每日一题(16) codeforces 1041B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/26</span><a class="archive-post-title" href= "/2018/09/26/Flask-笔记/" >Flask 笔记</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/26</span><a class="archive-post-title" href= "/2018/09/26/每日一题-15-codeforces-1041A/" >每日一题(15) codeforces 1041A</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/26</span><a class="archive-post-title" href= "/2018/09/26/数据结构与算法-5-堆排序/" >数据结构与算法(5) 堆排序</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/25</span><a class="archive-post-title" href= "/2018/09/25/每日一题-14-codeforces1036D/" >每日一题(14) codeforces1036D</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/24</span><a class="archive-post-title" href= "/2018/09/24/每日一题-13-BZOJ1026/" >每日一题(13) BZOJ1026</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/23</span><a class="archive-post-title" href= "/2018/09/23/每日一题-12-BZOJ1833/" >每日一题(12) BZOJ1833</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2018/09/22/机器学习-2-决策树-ID3算法实现/" >机器学习(2) 决策树(ID3算法实现)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/21</span><a class="archive-post-title" href= "/2018/09/21/每日一题-11-HDU4734/" >每日一题(11) HDU4734</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/20</span><a class="archive-post-title" href= "/2018/09/20/每日一题-10-POJ3252/" >每日一题(10) POJ3252</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/20</span><a class="archive-post-title" href= "/2018/09/20/数据结构与算法-4-堆-优先队列/" >数据结构与算法(4) 堆(优先队列)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/19</span><a class="archive-post-title" href= "/2018/09/19/每日一题-9-HDU3652/" >每日一题(9) HDU3652</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/18</span><a class="archive-post-title" href= "/2018/09/18/每日一题-8-HDU2089/" >每日一题(8) HDU2089不要62</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/18</span><a class="archive-post-title" href= "/2018/09/18/数据结构与算法-3-稳定排序与非稳定排序/" >数据结构与算法(3) 稳定排序与非稳定排序</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/17</span><a class="archive-post-title" href= "/2018/09/17/数据结构与算法-2-加权随机算法的Python实现/" >数据结构与算法(2) 加权随机算法的Python实现</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/17</span><a class="archive-post-title" href= "/2018/09/17/每日一题-7-codeforces-1036C/" >每日一题(7) codeforces 1036C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/15</span><a class="archive-post-title" href= "/2018/09/15/机器学习-1-k-近邻算法-KNN/" >机器学习(1) k-近邻算法(KNN)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/14</span><a class="archive-post-title" href= "/2018/09/14/每日一题-6-codeforces-1036B/" >每日一题(6) codeforces 1036B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/14</span><a class="archive-post-title" href= "/2018/09/14/数据结构与算法-1-二叉堆/" >数据结构与算法(1)-二叉堆</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/13</span><a class="archive-post-title" href= "/2018/09/13/每日一题-5-codeforces-1036A/" >每日一题(5)codeforces 1036A</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/12</span><a class="archive-post-title" href= "/2018/09/12/每日一题-4-codeforces-1038D/" >每日一题(4) codeforces 1038D</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/11</span><a class="archive-post-title" href= "/2018/09/11/Redis学习-2-Windows下安装和可视化工具安装/" >Redis学习(2)Windows下安装和可视化工具安装</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/11</span><a class="archive-post-title" href= "/2018/09/11/每日一题-3-codeforces-1038C/" >每日一题(3) codeforces 1038C</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/11</span><a class="archive-post-title" href= "/2018/09/11/Redis学习-1-Linux下安装/" >Redis学习(1) Linux下安装</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/10</span><a class="archive-post-title" href= "/2018/09/10/每日一题-2-codefroces-1038B/" >每日一题(2) codefroces 1038B</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/09</span><a class="archive-post-title" href= "/2018/09/09/每日一题-1-codeforces-1038A/" >每日一题(1) codeforces 1038A</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="Maven"><span class="iconfont-archer">&#xe606;</span>Maven</span>
    
        <span class="sidebar-tag-name" data-tags="排序"><span class="iconfont-archer">&#xe606;</span>排序</span>
    
        <span class="sidebar-tag-name" data-tags="树"><span class="iconfont-archer">&#xe606;</span>树</span>
    
        <span class="sidebar-tag-name" data-tags="树状数组"><span class="iconfont-archer">&#xe606;</span>树状数组</span>
    
        <span class="sidebar-tag-name" data-tags="思维"><span class="iconfont-archer">&#xe606;</span>思维</span>
    
        <span class="sidebar-tag-name" data-tags="数位dp"><span class="iconfont-archer">&#xe606;</span>数位dp</span>
    
        <span class="sidebar-tag-name" data-tags="gcd"><span class="iconfont-archer">&#xe606;</span>gcd</span>
    
        <span class="sidebar-tag-name" data-tags="贪心"><span class="iconfont-archer">&#xe606;</span>贪心</span>
    
        <span class="sidebar-tag-name" data-tags="优先队列"><span class="iconfont-archer">&#xe606;</span>优先队列</span>
    
        <span class="sidebar-tag-name" data-tags="构造"><span class="iconfont-archer">&#xe606;</span>构造</span>
    
        <span class="sidebar-tag-name" data-tags="数论"><span class="iconfont-archer">&#xe606;</span>数论</span>
    
        <span class="sidebar-tag-name" data-tags="素数"><span class="iconfont-archer">&#xe606;</span>素数</span>
    
        <span class="sidebar-tag-name" data-tags="规律"><span class="iconfont-archer">&#xe606;</span>规律</span>
    
        <span class="sidebar-tag-name" data-tags="STL"><span class="iconfont-archer">&#xe606;</span>STL</span>
    
        <span class="sidebar-tag-name" data-tags="Map"><span class="iconfont-archer">&#xe606;</span>Map</span>
    
        <span class="sidebar-tag-name" data-tags="数学"><span class="iconfont-archer">&#xe606;</span>数学</span>
    
        <span class="sidebar-tag-name" data-tags="DFS"><span class="iconfont-archer">&#xe606;</span>DFS</span>
    
        <span class="sidebar-tag-name" data-tags="模拟"><span class="iconfont-archer">&#xe606;</span>模拟</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Redis"><span class="iconfont-archer">&#xe60a;</span>Redis</span>
    
        <span class="sidebar-category-name" data-categories="Java"><span class="iconfont-archer">&#xe60a;</span>Java</span>
    
        <span class="sidebar-category-name" data-categories="数据结构与算法"><span class="iconfont-archer">&#xe60a;</span>数据结构与算法</span>
    
        <span class="sidebar-category-name" data-categories="Flask"><span class="iconfont-archer">&#xe60a;</span>Flask</span>
    
        <span class="sidebar-category-name" data-categories="机器学习"><span class="iconfont-archer">&#xe60a;</span>机器学习</span>
    
        <span class="sidebar-category-name" data-categories="每日一题"><span class="iconfont-archer">&#xe60a;</span>每日一题</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "InTheBloodHorse"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
        <div class="site-search">
  <div class="algolia-popup popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="iconfont-archer">&#xe609;</i>
    </span>
  </div>
</div>
        <script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.8.0/dist/instantsearch.min.js" defer></script>
        <script src="/scripts/search.js" defer></script>
    
    <!-- busuanzi  -->
    
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->    
     
    </body>
</html>


